{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总体架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;早期的机器阅读理解模型大多基于检索技术，但是信息检索主要依赖关键词的匹配，而在很多情况下，单纯依靠问题和文章片段的文字匹配找到的答案与问题并不相关。随着深度学习的发展，机器阅读理解步入了神经网络时代。本文将介绍基于深度学习的机器阅读理解模型的架构，探究其提升性能的原因。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;基于深度学习的MRC模型构造各异，但是经过多年的实践和探索，逐渐形成了稳定框架结构。本节将介绍MRC模型共有的总体架构。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;MRC模型的输入为文章和问题。因此，首先要对这两部分进行数字化编码，将其变成可以被计算机处理的信息单元。在编码的过程中，模型需要保留原有语句在文章中的语义。因此，每个单词、短语和句子的编码必须建立在理解上下文的基础上。我们把模型中进行编码的模块称为编码层。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;接下来，由于文章和问题之间存在相关性，所以模型需要建立文章和问题之间的联系。例如，如果问题中出现关键词“河流”，而文章中出现关键词“长江”。虽然两个词不完全一样，但是其语义编码接近。因此，文章中“长江”一词以及邻近的语句将成为模型回答问题时的重点关注对象。这可以通过注意力机制加以解决。在这个过程中，MRC模型将文章和问题的语义结合在一起进行考量，进一步加深模型对于两者的理解。我们将这个模块称为交互层。交互层可以让模型聚焦文章和问题的语义联系，借助于文章的语义分析加深对问题的理解，同时借助于问题的语义分析加深对文章的理解。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;经过交互层，模型建立起文章和问题之间的语义联系，接下来就可以预测问题的答案了。完成预测功能的模块称为输出层。MRC任务的答案有多种类型，因此输出层的具体形式需要和任务的答案类型相关联。此外，输出层确定模型优化时的评估函数和损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编码层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;与其他基于深度学习的自然语言处理模型类似，MRC模型首先需要将文字形式的文章和问题转化成词向量。编码层一般采用类似的分布式算法对文本进行分词和向量化处理，然后加入字符编码等更丰富的信息，并采用上下文编码获得每个单词在具体语境中的含义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词表的建立与初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;首先，模型对训练文本进行分词以得到其中所有的单词。然后，根据阈值选取出现次数超过一定次数的单词组成词表，词表以外的单词视为非词表词（Out-Of-Vocabulary, OOV），用特殊单词<UNK\\>表示。这样，模型可以得到一个大小为|V|的词表，每个词表中的词用一个d维向量表示。接下来，我们有两种方法获得词表中的单词向量：\n",
    "    <br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1、保持词表向量不变，即采用预训练词表中的向量（如Word2Vec的300维向量），在训练过程中不进行改变；\n",
    "    <br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2、将词表中的向量视为参数，在训练过程中和其他参数一起求导并优化。这里，既可以使用预训练词表向量进行初始化，也可以选择随机初始化。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;第一种选择的优势是模型参数少，训练初期收敛较快；第二种选择的优势是可以根据实际数据调整词向量的值，以达到更好的训练效果。而采用预训练词表向量初始化一般可以使得模型在优化的最初几轮获得明显比随机初始化方法更优的结果。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;在编码层中，为了更准确地表示每个单词在语句中的语义，除了词向量外，还经常对命名实体（named entity）和词性（part-of-speech）进行向量化处理。如果命名实体共有N种，则建立大小为N的命名实体表，每种命名实体用一个长度为d_N的向量表示；如果词性共有P种，则建立大小为P的词性表，每种词性用一个长度为d_P的向量表示。两个表中的向量均为可训练的参数。然后，用文本分析包，如spaCy，获得文章和问题中的每个词的命名实体和词性，再将对应向量拼接在词向量之后。由于一个词的命名实体属性与词性和这个词所在的语句有关，因此用这种方式获得向量编码可以更好地表示单词的语义，在许多模型中性能都有明显的提升。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;另一种在机器阅读理解中非常有效的单词编码是精确匹配（exact matching）编码。exact matching编码适用于文章中的单词。对于文章中的单词w，检查w是否出现在问题中：如果是，w的精确匹配编码为1，否则为0，然后将这个二进制位拼接在单词向量后。精确匹配编码可以使模型快速找到文章中出现了问题单词的部分，而许多问题的答案往往就在这部分内容的附近。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;文本处理中时常会出现拼写错误，这时通过字符组合，往往可以识别正确的单词形式。此外，许多语言中存在词根的概念，即词的一部分是一个常见且有固定含义的子词。在单词的理解中，字符和子词具有很强的辅助作用。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;为了更好地利用字符信息，在编码层中采用字符编码，即每个字符用一个向量表示。但是，由于单词的长度不一，每个单词可能有不同个数的字符向量。为了产生一个固定长度的字符信息向量，我们可以将多个字符向量合并成一个编码。最常用的模型是字符CNN。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;设一个单词有K个字符，且对应的K个字符向量为（c_1, c_2, ..., c_k），每个向量维度为c。字符CNN利用一个窗口大小为W且有f个输出通道的CNN获得（K-W+1）个f维向量。然后，采用最大池化方法求得这些向量每一个维度上的最大值，形成一个f维向量作为结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符卷积神经网络Char-CNN的PyTorch实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNNMaxpooling(nn.Module):\n",
    "    # char_num为字符表大小，char_dim为字符向量长度，window_size为CNN窗口长度，out_channels为CNN输出通道数\n",
    "    def __init__(self, char_num, char_dim, window_size, out_channels):\n",
    "        super(CharCNNMaxpooling, self).__init__()\n",
    "        # 字符表向量，共有char_num个向量，每个维度为char_dim\n",
    "        self.char_embed = nn.Embedding(num_embeddings=char_num, embedding_dim=char_dim)\n",
    "        # 1个输入通道，out_channels个输出通道，过滤器大小为window_size*char_dim\n",
    "        self.cnn = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, char_dim))\n",
    "\n",
    "    # 输入char_ids为batch组文本，每个文本长度为seq_len，每个词含word_len个字符编号（0~char_num-1），输入维度为batch*seq_len*word_len\n",
    "    # 输出res为所有单词的字符向量表示，维度是batch*seq_len*out_channels\n",
    "    def forward(self, char_ids):\n",
    "        # 根据字符编号得到字符向量，结果维度为batch*seq_len*word_len*char_dim\n",
    "        x = self.char_embed(char_ids)\n",
    "        # 合并前两维并变成单通道，结果维度（batch*seq_len）*1*word_len*char_dim\n",
    "        x_unsqueeze = x.view(-1, x.shape[2], x.shape[3]).unsqueeze(1)\n",
    "        # CNN，结果维度为（batch*seq_len）*out_channels*new_seq_len*1\n",
    "        x_cnn = self.cnn(x_unsqueeze)\n",
    "        # 删除最后一维，结果维度为（batch*seq）*out_channels*new_seq_len\n",
    "        x_cnn_result = x_cnn.squeeze(3)\n",
    "        # 最大池化，遍历最后一维求最大值，结果维度为（batch*seq_len）*out_channels\n",
    "        res, _ = x_cnn_result.max(2)  # \n",
    "        # print('res_如下:')\n",
    "        # print(res)\n",
    "        # print('res_: {shape}'.format(shape=res.shape))\n",
    "        return res.view(x.shape[0], x.shape[1], -1)  # x.shape[0] = batch, x.shape[1] = seq_len，不确定第2个维度是几，但是一定指定前两个维度的大小，所以这里用-1代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "char_ids: torch.Size([10, 20, 12])\nres: torch.Size([10, 20, 8])\ntensor([[[ 0.6529,  0.8465,  0.4470,  ...,  1.4186,  0.8840,  0.5334],\n         [ 0.3931,  1.1519,  0.6541,  ...,  0.8053,  1.0912,  0.9075],\n         [ 1.1718,  1.2721,  0.8915,  ...,  1.2315,  0.8225,  0.5993],\n         ...,\n         [ 0.3707,  0.8362,  0.3265,  ...,  1.7615,  1.3467,  1.0405],\n         [ 0.9671,  1.0019,  0.5029,  ...,  1.5247,  1.1616,  1.0269],\n         [ 0.3161,  1.0389,  0.9601,  ...,  1.4771,  1.2479,  1.4900]],\n\n        [[ 0.4622,  1.3565,  0.9146,  ...,  1.8216,  1.0728,  0.7849],\n         [ 1.4459,  0.7593,  0.7322,  ...,  0.7574,  1.2987,  1.0229],\n         [ 0.8910,  0.9636,  0.5123,  ...,  0.7922,  0.6371,  0.8367],\n         ...,\n         [ 1.5457,  1.1434,  0.7236,  ...,  1.3477,  0.6684,  1.3263],\n         [ 0.3809,  1.1418,  0.3265,  ...,  0.7690,  1.0942,  0.7274],\n         [ 0.8428,  0.8657,  0.9694,  ...,  1.2150,  1.0022,  1.0709]],\n\n        [[ 0.7381,  0.8110,  0.8606,  ...,  1.7145,  1.1456,  1.3516],\n         [ 0.5306,  0.7321,  0.7269,  ...,  1.8817,  0.9892,  0.6081],\n         [ 0.7681,  1.5899,  0.9694,  ...,  1.3789,  0.9456,  0.9102],\n         ...,\n         [-0.0202,  0.8903,  0.7236,  ...,  1.0766,  0.6739,  0.8524],\n         [ 0.3953,  1.2157,  1.1734,  ...,  0.6691,  0.5813,  1.0864],\n         [ 1.4352,  0.9237,  0.3999,  ...,  0.3335,  0.9355,  1.0347]],\n\n        ...,\n\n        [[ 0.6724,  1.3766,  0.4145,  ...,  1.6510,  0.7578,  1.2121],\n         [ 0.0899,  0.9177,  0.1930,  ...,  1.1326,  0.4816,  0.7177],\n         [ 0.2381,  1.3531,  0.9816,  ...,  0.9080,  0.5807,  0.9451],\n         ...,\n         [ 0.1177,  0.7812,  0.4341,  ...,  0.9952,  0.9987,  0.5933],\n         [ 0.6133,  0.6906,  0.3384,  ...,  0.4198,  1.0496,  0.7382],\n         [ 0.3542,  1.3809,  0.6532,  ...,  1.1309,  0.8994,  0.6897]],\n\n        [[ 1.0584,  0.6592,  0.3019,  ...,  1.4882,  1.0489,  0.6695],\n         [ 1.0821,  0.7980,  0.3352,  ...,  0.8616,  1.8076,  1.0552],\n         [ 1.1696,  0.9259,  0.5823,  ...,  2.1087,  1.1197,  1.5441],\n         ...,\n         [ 0.5616,  0.3050,  0.3146,  ...,  1.0774,  1.4466,  0.6489],\n         [ 0.8484,  0.8199,  0.6766,  ...,  1.1964,  1.3193,  0.9270],\n         [ 0.6931,  1.1048,  0.5897,  ...,  1.1231,  1.0932,  1.1759]],\n\n        [[ 0.9204,  0.4453,  0.3549,  ...,  1.1322,  1.2749,  0.9397],\n         [ 0.1800,  0.8184,  0.9146,  ...,  1.4425,  0.8817,  0.9452],\n         [ 0.5871,  1.1965,  0.8250,  ...,  0.9948,  1.1243,  0.9721],\n         ...,\n         [ 0.6591,  1.4798,  0.7063,  ...,  0.7222,  0.6736,  1.3032],\n         [ 1.3091,  1.0825,  0.8748,  ...,  1.3460,  1.2448,  1.1394],\n         [ 0.4832,  0.8044,  0.5766,  ...,  1.0258,  0.9987,  0.7614]]],\n       grad_fn=<ViewBackward>)\n"
    }
   ],
   "source": [
    "batch = 10  # batch\n",
    "seq_len = 20  # 每个文本长度\n",
    "word_len = 12  # 单词中字符个数\n",
    "char_num = 26  # 字符表大小\n",
    "char_dim = 10  # 字符向量长度\n",
    "window_size = 3\n",
    "out_channels = 8\n",
    "char_cnn = CharCNNMaxpooling(char_num=char_num, char_dim=char_dim, window_size=window_size, out_channels=out_channels)\n",
    "char_ids = torch.LongTensor(batch, seq_len, word_len).random_(0, char_num - 1)\n",
    "print('char_ids: {shape}'.format(shape=char_ids.shape))\n",
    "res = char_cnn(char_ids)\n",
    "print('res: {shape}'.format(shape=res.shape))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CharCNNMaxpooling(\n  (char_embed): Embedding(26, 10)\n  (cnn): Conv2d(1, 8, kernel_size=(3, 10), stride=(1, 1))\n)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "char_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上下文编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;理解一个单词需要考虑它的上下文，很多具有多义性的单词需要考虑它周围的语句才能确定其明确含义。然而，基于词表的单词向量是固定的，不会随上下文变化。这就会导致同一个词在不同的语句中语义不同但其向量表示完全相同的情况。因此，编码层需要对每个单词生成上下文编码（contextual embedding）。这种编码会随着单词的上下文不同而发生改变，从而反映单词在当前语句中的含义。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;在深度学习中，为了实现上下文语义的理解通常采用单词之间的信息传递。RNN是最常用的上下文编码生成结构，因为RNN利用相邻单词间的状态向量转移实现语义信息的传递。为了更有效地利用每个单词左右两个方向的语句信息，常采用双向循环神经网络（bidirectional RNN）获得上下文编码。而许多模型还采用了多层RNN，用于提取更高级的上下文语义，获得更好的效果。以下是多层双向RNN获得文本单词上下文编码的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualEmbedding(nn.Module):\n",
    "    # word_dim为词向量维度，state_dim为RNN状态维度，rnn_layer为RNN层数\n",
    "    def __init__(self, word_dim, state_dim, rnn_layer):\n",
    "        super(ContextualEmbedding, self).__init__()\n",
    "        # 多层双向GRU\n",
    "        self.rnn = nn.GRU(input_size=word_dim, hidden_size=state_dim, num_layers=rnn_layer, bidirectional=True, batch_first=True)\n",
    "    \n",
    "    # 输入x为batch组文本，每个文本长度为seq_len，每个词用一个word_dim维向量表示，输入维度为batch*seq_len*word_dim\n",
    "    # 输出res为所有单词的上下文向量表示，维度是batch*seq_len*out_dim\n",
    "    def forward(self, x):\n",
    "        res, _ = self.rnn(x)  # 输出维度是batch*seq_len*out_dim，其中out_dim=2*state_dim，包含两个方向\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([10, 20, 200])\ntensor([[[ 0.0080,  0.0752,  0.0691,  ..., -0.1804, -0.1286, -0.0760],\n         [ 0.0345,  0.2315, -0.0525,  ..., -0.0794, -0.0285, -0.0648],\n         [-0.0214,  0.2942,  0.0620,  ...,  0.0956,  0.0647, -0.1344],\n         ...,\n         [ 0.0417,  0.2764, -0.0351,  ...,  0.0393, -0.0262, -0.0384],\n         [-0.0468,  0.1864, -0.0866,  ...,  0.1061, -0.0113, -0.0976],\n         [ 0.0095,  0.1128, -0.2422,  ...,  0.0659, -0.0028, -0.0171]],\n\n        [[ 0.0631,  0.0126, -0.0295,  ..., -0.0325,  0.1695, -0.0288],\n         [ 0.0397, -0.0197, -0.1112,  ...,  0.0062,  0.0411, -0.0849],\n         [-0.0527, -0.0169, -0.1902,  ..., -0.0864, -0.1091, -0.0711],\n         ...,\n         [ 0.0062,  0.1072,  0.0422,  ...,  0.0799, -0.4598, -0.2337],\n         [-0.0610,  0.2202,  0.0625,  ...,  0.1482, -0.3998, -0.0943],\n         [-0.1604,  0.2246,  0.0001,  ...,  0.0522, -0.2840, -0.0291]],\n\n        [[-0.0154,  0.1051,  0.2525,  ..., -0.1313,  0.0892, -0.1459],\n         [-0.0266,  0.1105,  0.1698,  ..., -0.1089,  0.1456, -0.0983],\n         [-0.0032,  0.0250,  0.0459,  ..., -0.0804,  0.1711, -0.1853],\n         ...,\n         [-0.2064, -0.0148,  0.2430,  ...,  0.0067, -0.3654,  0.0091],\n         [-0.1856, -0.0918,  0.0723,  ..., -0.0454, -0.2871,  0.0867],\n         [-0.1094, -0.1381, -0.1590,  ..., -0.0582, -0.1691,  0.0129]],\n\n        ...,\n\n        [[ 0.0167,  0.0985,  0.1330,  ..., -0.0808, -0.0648, -0.1878],\n         [-0.0518,  0.1453,  0.1311,  ..., -0.0497, -0.1100, -0.1148],\n         [ 0.0055,  0.1799,  0.1705,  ...,  0.0670,  0.0283, -0.0726],\n         ...,\n         [-0.2448,  0.1991,  0.1183,  ...,  0.0930, -0.3328, -0.1171],\n         [-0.1200,  0.1959, -0.0200,  ..., -0.0031, -0.3103, -0.0194],\n         [-0.1273,  0.1389, -0.1280,  ...,  0.0214, -0.2764, -0.0656]],\n\n        [[ 0.0403,  0.0098, -0.1307,  ..., -0.1616,  0.1155,  0.0369],\n         [-0.0956,  0.0845, -0.3356,  ..., -0.1357,  0.1722,  0.0077],\n         [-0.0986,  0.1509, -0.4562,  ..., -0.0717,  0.0898, -0.0061],\n         ...,\n         [-0.2795,  0.0980, -0.2275,  ..., -0.1987, -0.2473, -0.1656],\n         [-0.2555,  0.1401, -0.2023,  ..., -0.1787, -0.2202, -0.1396],\n         [-0.0793, -0.0400, -0.1914,  ..., -0.1036, -0.1081, -0.0279]],\n\n        [[-0.1273,  0.0462, -0.0474,  ..., -0.0075, -0.0243, -0.1874],\n         [-0.2621,  0.0804, -0.0725,  ...,  0.0541,  0.1171, -0.0737],\n         [-0.2053,  0.0947, -0.0931,  ..., -0.0509,  0.1275, -0.0494],\n         ...,\n         [ 0.0353,  0.2012, -0.0735,  ..., -0.4523, -0.2118,  0.0372],\n         [-0.0039,  0.3029, -0.1753,  ..., -0.3233, -0.1137, -0.0528],\n         [ 0.0021,  0.3868, -0.1274,  ..., -0.2236, -0.0454,  0.0569]]],\n       grad_fn=<TransposeBackward0>)\n"
    }
   ],
   "source": [
    "batch = 10\n",
    "seq_len = 20\n",
    "word_dim = 50\n",
    "state_dim = 100\n",
    "rnn_layer = 2\n",
    "x = torch.randn(batch, seq_len, word_dim)\n",
    "context_embed = ContextualEmbedding(word_dim=word_dim, state_dim=state_dim, rnn_layer=rnn_layer)\n",
    "res = context_embed(x)\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;研究者进一步发现，在大规模自然语言处理任务上进行预训练，然后将预训练模型中的循环神经网络参数用用机器阅读理解，可以获得明显的性能提升，如CoVe模型在大量机器翻译数据上训练序列到序列模型，然后将编码器部分的循环神经网络用于SQuAD数据集，F1分数提高了近4%。\n",
    "\n",
    "&emsp;&emsp;&emsp;&emsp;综上所述，在编码层中，每个问题单词由词表向量、命名实体向量、词性向量、字符编码、上下文编码组成，而每个文章单词除了以上5中向量外，还有精确匹配编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交互层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;机器阅读理解模型在编码层中获得了文章和问题中单词的语义向量表示，但两部分的编码是基本独立的。为了获得最终答案，模型需要交互处理文章和问题中的信息。因此，模型在交互层中将文章和问题的语义信息融合，基于"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python36564bitmrccondaf2fda53e5a1a4db7b763f220d2468ca5",
   "display_name": "Python 3.6.5 64-bit ('MRC': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
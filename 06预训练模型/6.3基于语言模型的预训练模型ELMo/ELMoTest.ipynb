{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFkB-Uxy34G",
        "colab_type": "code",
        "outputId": "d1429cbb-f63e-4fc0-8659-5113d327b2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  8 02:46:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XupnRIEznj-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ELMo预训练模型的使用"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIJ9Y9a5oBVA",
        "colab_type": "code",
        "outputId": "5fcea7b8-b2b7-4541-b938-a61732d1722d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd ./drive/My\\ Drive/PyTorch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuPUzq-toVJL",
        "colab_type": "code",
        "outputId": "012b840d-352d-4fb1-e5c7-4f56a901c89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.16.0)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.1)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from allennlp) (5.7)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.10.14)\n",
            "Requirement already satisfied: pytorch-transformers==1.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n",
            "Collecting spacy<2.2,>=2.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.1)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.5.0+cu101)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: conllu==1.3.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.6.2)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.8)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.13.19)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (20.6.0)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.1)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.18.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (1.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from responses>=0.7->allennlp) (1.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (0.1.91)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Using cached https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Using cached https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.6.0)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Using cached https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.2.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->allennlp) (0.16.0)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (47.1.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.19 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.16.19)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (5.1.0)\n",
            "Requirement already satisfied: greenlet>=0.4.16; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.16)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.15.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.15.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (20.4)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.8.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: blis, preshed, thinc, spacy\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: thinc 7.3.1\n",
            "    Uninstalling thinc-7.3.1:\n",
            "      Successfully uninstalled thinc-7.3.1\n",
            "  Found existing installation: spacy 2.2.2\n",
            "    Uninstalling spacy-2.2.2:\n",
            "      Successfully uninstalled spacy-2.2.2\n",
            "Successfully installed blis-0.2.4 preshed-2.0.1 spacy-2.1.9 thinc-7.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Yv8nP7oZz2",
        "colab_type": "code",
        "outputId": "7aeaa48b-d9a2-421b-8e12-54926e8fe591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udM_vkbww4A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "from allennlp.nn.util import remove_sentence_boundaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GOw1rg8xboR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 预训练模型下载"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5EzEeUqxeVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds9VrIXSxzBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获得ELMo编码器的类"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UacK-GF6x_Ou",
        "colab_type": "code",
        "outputId": "6af13a5d-4f52-41df-a457-075e49e5ca51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "elmo_bilm = ElmoEmbedder(options_file=options_file, weight_file=weight_file).elmo_bilm\n",
        "elmo_bilm.cuda()\n",
        "sentences = [['Taday', 'is', 'sunny', '.'], ['Hello', '!']]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 336/336 [00:00<00:00, 1040831.72B/s]\n",
            "100%|██████████| 374434792/374434792 [00:20<00:00, 18017369.50B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5EhNwkzyjTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "f221c153-609e-4a90-f52a-b4c5e0ae915d"
      },
      "source": [
        "elmo_bilm.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_ElmoBiLm(\n",
              "  (_token_embedder): _ElmoCharacterEncoder(\n",
              "    (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "    (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "    (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "    (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "    (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "    (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "    (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "    (_highways): Highway(\n",
              "      (_layers): ModuleList(\n",
              "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  )\n",
              "  (_elmo_lstm): ElmoLstm(\n",
              "    (forward_layer_0): LstmCellWithProjection(\n",
              "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "    )\n",
              "    (backward_layer_0): LstmCellWithProjection(\n",
              "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "    )\n",
              "    (forward_layer_1): LstmCellWithProjection(\n",
              "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "    )\n",
              "    (backward_layer_1): LstmCellWithProjection(\n",
              "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RroEgy6_3Fql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获得所有单词的字符ID，维度为batch_size(2)*max_sentence_len(4)*word_len(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3zrGw1k3hFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "1e3e1ba2-8e71-41bf-decf-1cfc4470d4c2"
      },
      "source": [
        "character_ids = batch_to_ids(sentences).cuda();character_ids"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[259,  85,  98, 101,  98, 122, 260, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261],\n",
              "         [259, 106, 116, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261],\n",
              "         [259, 116, 118, 111, 111, 122, 260, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261],\n",
              "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261]],\n",
              "\n",
              "        [[259,  73, 102, 109, 109, 112, 260, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261],\n",
              "         [259,  34, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
              "          261, 261, 261, 261, 261, 261, 261, 261],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0],\n",
              "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "            0,   0,   0,   0,   0,   0,   0,   0]]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKlJlL1m48Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f907dea-fe45-4e39-d451-44387566084a"
      },
      "source": [
        "character_ids.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlQpZOKx3rw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获得ELMo输出"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQXH1fKq3817",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5caa3774-210b-40fb-8f79-bc79c4c380d6"
      },
      "source": [
        "bilm_output = elmo_bilm(character_ids);bilm_output"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activations': [tensor([[[ -3.1190,   7.4196, -14.9239,  ...,   2.8717,   5.6098,   6.6934],\n",
              "           [ -0.7891,  -0.5492,   0.1154,  ...,  -0.0757,   0.0520,  -0.3345],\n",
              "           [  0.1915,   0.2300,  -0.2894,  ...,  -0.0645,   0.5810,   0.2177],\n",
              "           [  0.0589,  -0.6212,   0.0233,  ...,   0.6718,  -0.7320,   0.6754],\n",
              "           [ -0.8872,  -0.2004,  -1.0601,  ...,  -0.2655,   0.2115,   0.1977],\n",
              "           [ -6.0587,  13.7965, -15.6421,  ...,  21.0167,  16.7111,   6.5752]],\n",
              "  \n",
              "          [[ -3.1190,   7.4196, -14.9239,  ...,   2.8717,   5.6098,   6.6934],\n",
              "           [  0.1743,  -1.4072,  -0.1939,  ...,  -0.6675,  -0.2126,   0.4458],\n",
              "           [ -1.3351,   0.6297,  -1.4650,  ...,   0.0295,   0.6432,   0.8339],\n",
              "           [ -6.0587,  13.7965, -15.6421,  ...,  21.0167,  16.7111,   6.5752],\n",
              "           [ -0.0000,  -0.0000,   0.0000,  ...,   0.0000,  -0.0000,  -0.0000],\n",
              "           [ -0.0000,  -0.0000,   0.0000,  ...,   0.0000,  -0.0000,  -0.0000]]],\n",
              "         device='cuda:0'),\n",
              "  tensor([[[ 0.0570,  0.0479, -0.0333,  ...,  0.3608,  1.1422,  1.0433],\n",
              "           [-0.2670, -0.0881, -0.1534,  ...,  0.0034,  0.2856, -0.0127],\n",
              "           [-0.4867, -0.2524, -0.0537,  ...,  0.1755,  0.9264,  0.7234],\n",
              "           [-0.0058, -0.5936, -0.2885,  ...,  0.1183,  0.7336,  0.4271],\n",
              "           [-0.9750, -0.3586, -0.0106,  ..., -0.0282, -0.0177,  0.0600],\n",
              "           [-0.3244, -1.5545, -1.6040,  ...,  0.1011,  1.7162,  3.0000]],\n",
              "  \n",
              "          [[ 0.0442,  0.0532, -0.0313,  ...,  1.5467,  1.3146,  1.2128],\n",
              "           [ 0.0792, -0.9959, -1.3092,  ..., -0.3931, -0.0195, -0.5935],\n",
              "           [-0.4540, -1.2215, -0.1930,  ...,  0.1977,  0.1381, -0.1968],\n",
              "           [-0.0710, -1.0381, -1.4527,  ...,  0.1026,  1.7142,  3.0000],\n",
              "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
              "         device='cuda:0'),\n",
              "  tensor([[[ 1.0161e-01,  1.4911e-01, -2.7962e-01,  ..., -3.5844e-01,\n",
              "             1.2606e+00,  4.1881e-01],\n",
              "           [-1.1359e+00, -1.0042e+00, -3.6454e-01,  ..., -1.5923e-01,\n",
              "             5.8588e-01, -1.4881e-01],\n",
              "           [-1.3656e+00, -9.1023e-01, -8.8036e-02,  ..., -2.6436e-01,\n",
              "             2.5936e+00,  1.9032e+00],\n",
              "           [-4.2545e-01, -7.8282e-01,  1.5677e-01,  ...,  2.5359e-01,\n",
              "             9.6101e-01,  3.5806e-01],\n",
              "           [-7.9414e-01, -4.8740e-01, -1.6544e+00,  ..., -1.0655e-03,\n",
              "            -9.2814e-02,  6.3544e-02],\n",
              "           [-9.3455e-01, -2.3880e+00, -3.5407e+00,  ...,  2.3629e-01,\n",
              "             1.6460e+00,  4.1650e+00]],\n",
              "  \n",
              "          [[ 1.0363e-01,  1.5480e-01, -3.0737e-01,  ...,  1.5404e+00,\n",
              "             5.8958e-01,  9.2198e-01],\n",
              "           [-3.8214e-01, -1.5724e+00, -1.7789e+00,  ..., -6.9299e-01,\n",
              "             2.7527e-02,  5.2571e-03],\n",
              "           [-1.3691e-01, -1.2817e+00, -7.3394e-01,  ...,  2.1262e-01,\n",
              "             4.1552e-01,  3.9256e-02],\n",
              "           [-9.2670e-01, -1.5639e+00, -3.2793e+00,  ...,  2.4452e-01,\n",
              "             1.5768e+00,  4.1844e+00],\n",
              "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00],\n",
              "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00]]], device='cuda:0')],\n",
              " 'mask': tensor([[1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 0, 0]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoR6SGP44EIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ELMo编码"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJELYa6p4J9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "24486ecd-8208-4127-b430-de2bdbd92f0d"
      },
      "source": [
        "layer_activations = bilm_output['activations'];layer_activations"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[ -3.1190,   7.4196, -14.9239,  ...,   2.8717,   5.6098,   6.6934],\n",
              "          [ -0.7891,  -0.5492,   0.1154,  ...,  -0.0757,   0.0520,  -0.3345],\n",
              "          [  0.1915,   0.2300,  -0.2894,  ...,  -0.0645,   0.5810,   0.2177],\n",
              "          [  0.0589,  -0.6212,   0.0233,  ...,   0.6718,  -0.7320,   0.6754],\n",
              "          [ -0.8872,  -0.2004,  -1.0601,  ...,  -0.2655,   0.2115,   0.1977],\n",
              "          [ -6.0587,  13.7965, -15.6421,  ...,  21.0167,  16.7111,   6.5752]],\n",
              " \n",
              "         [[ -3.1190,   7.4196, -14.9239,  ...,   2.8717,   5.6098,   6.6934],\n",
              "          [  0.1743,  -1.4072,  -0.1939,  ...,  -0.6675,  -0.2126,   0.4458],\n",
              "          [ -1.3351,   0.6297,  -1.4650,  ...,   0.0295,   0.6432,   0.8339],\n",
              "          [ -6.0587,  13.7965, -15.6421,  ...,  21.0167,  16.7111,   6.5752],\n",
              "          [ -0.0000,  -0.0000,   0.0000,  ...,   0.0000,  -0.0000,  -0.0000],\n",
              "          [ -0.0000,  -0.0000,   0.0000,  ...,   0.0000,  -0.0000,  -0.0000]]],\n",
              "        device='cuda:0'),\n",
              " tensor([[[ 0.0570,  0.0479, -0.0333,  ...,  0.3608,  1.1422,  1.0433],\n",
              "          [-0.2670, -0.0881, -0.1534,  ...,  0.0034,  0.2856, -0.0127],\n",
              "          [-0.4867, -0.2524, -0.0537,  ...,  0.1755,  0.9264,  0.7234],\n",
              "          [-0.0058, -0.5936, -0.2885,  ...,  0.1183,  0.7336,  0.4271],\n",
              "          [-0.9750, -0.3586, -0.0106,  ..., -0.0282, -0.0177,  0.0600],\n",
              "          [-0.3244, -1.5545, -1.6040,  ...,  0.1011,  1.7162,  3.0000]],\n",
              " \n",
              "         [[ 0.0442,  0.0532, -0.0313,  ...,  1.5467,  1.3146,  1.2128],\n",
              "          [ 0.0792, -0.9959, -1.3092,  ..., -0.3931, -0.0195, -0.5935],\n",
              "          [-0.4540, -1.2215, -0.1930,  ...,  0.1977,  0.1381, -0.1968],\n",
              "          [-0.0710, -1.0381, -1.4527,  ...,  0.1026,  1.7142,  3.0000],\n",
              "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
              "        device='cuda:0'),\n",
              " tensor([[[ 1.0161e-01,  1.4911e-01, -2.7962e-01,  ..., -3.5844e-01,\n",
              "            1.2606e+00,  4.1881e-01],\n",
              "          [-1.1359e+00, -1.0042e+00, -3.6454e-01,  ..., -1.5923e-01,\n",
              "            5.8588e-01, -1.4881e-01],\n",
              "          [-1.3656e+00, -9.1023e-01, -8.8036e-02,  ..., -2.6436e-01,\n",
              "            2.5936e+00,  1.9032e+00],\n",
              "          [-4.2545e-01, -7.8282e-01,  1.5677e-01,  ...,  2.5359e-01,\n",
              "            9.6101e-01,  3.5806e-01],\n",
              "          [-7.9414e-01, -4.8740e-01, -1.6544e+00,  ..., -1.0655e-03,\n",
              "           -9.2814e-02,  6.3544e-02],\n",
              "          [-9.3455e-01, -2.3880e+00, -3.5407e+00,  ...,  2.3629e-01,\n",
              "            1.6460e+00,  4.1650e+00]],\n",
              " \n",
              "         [[ 1.0363e-01,  1.5480e-01, -3.0737e-01,  ...,  1.5404e+00,\n",
              "            5.8958e-01,  9.2198e-01],\n",
              "          [-3.8214e-01, -1.5724e+00, -1.7789e+00,  ..., -6.9299e-01,\n",
              "            2.7527e-02,  5.2571e-03],\n",
              "          [-1.3691e-01, -1.2817e+00, -7.3394e-01,  ...,  2.1262e-01,\n",
              "            4.1552e-01,  3.9256e-02],\n",
              "          [-9.2670e-01, -1.5639e+00, -3.2793e+00,  ...,  2.4452e-01,\n",
              "            1.5768e+00,  4.1844e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]], device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xFQFQzr4RY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 每个位置是否有单词"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhdUr3Uh5OcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1e92cb0c-8f15-4b06-e8f9-7d2fea9abfef"
      },
      "source": [
        "mask_with_bos_eos = bilm_output['mask'];mask_with_bos_eos"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 0, 0]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QttzxkCz5Vmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 去掉ELMo加上的句子开始和结束符"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN7-MS7D6rRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "3fb4926c-5ebd-450d-e21b-aa8f041feb48"
      },
      "source": [
        "without_bos_eos = [remove_sentence_boundaries(layer, mask_with_bos_eos) for layer in layer_activations];without_bos_eos"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([[[-0.7891, -0.5492,  0.1154,  ..., -0.0757,  0.0520, -0.3345],\n",
              "           [ 0.1915,  0.2300, -0.2894,  ..., -0.0645,  0.5810,  0.2177],\n",
              "           [ 0.0589, -0.6212,  0.0233,  ...,  0.6718, -0.7320,  0.6754],\n",
              "           [-0.8872, -0.2004, -1.0601,  ..., -0.2655,  0.2115,  0.1977]],\n",
              "  \n",
              "          [[ 0.1743, -1.4072, -0.1939,  ..., -0.6675, -0.2126,  0.4458],\n",
              "           [-1.3351,  0.6297, -1.4650,  ...,  0.0295,  0.6432,  0.8339],\n",
              "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
              "         device='cuda:0'), tensor([[1, 1, 1, 1],\n",
              "          [1, 1, 0, 0]], device='cuda:0')),\n",
              " (tensor([[[-0.2670, -0.0881, -0.1534,  ...,  0.0034,  0.2856, -0.0127],\n",
              "           [-0.4867, -0.2524, -0.0537,  ...,  0.1755,  0.9264,  0.7234],\n",
              "           [-0.0058, -0.5936, -0.2885,  ...,  0.1183,  0.7336,  0.4271],\n",
              "           [-0.9750, -0.3586, -0.0106,  ..., -0.0282, -0.0177,  0.0600]],\n",
              "  \n",
              "          [[ 0.0792, -0.9959, -1.3092,  ..., -0.3931, -0.0195, -0.5935],\n",
              "           [-0.4540, -1.2215, -0.1930,  ...,  0.1977,  0.1381, -0.1968],\n",
              "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
              "         device='cuda:0'), tensor([[1, 1, 1, 1],\n",
              "          [1, 1, 0, 0]], device='cuda:0')),\n",
              " (tensor([[[-1.1359e+00, -1.0042e+00, -3.6454e-01,  ..., -1.5923e-01,\n",
              "             5.8588e-01, -1.4881e-01],\n",
              "           [-1.3656e+00, -9.1023e-01, -8.8036e-02,  ..., -2.6436e-01,\n",
              "             2.5936e+00,  1.9032e+00],\n",
              "           [-4.2545e-01, -7.8282e-01,  1.5677e-01,  ...,  2.5359e-01,\n",
              "             9.6101e-01,  3.5806e-01],\n",
              "           [-7.9414e-01, -4.8740e-01, -1.6544e+00,  ..., -1.0655e-03,\n",
              "            -9.2814e-02,  6.3544e-02]],\n",
              "  \n",
              "          [[-3.8214e-01, -1.5724e+00, -1.7789e+00,  ..., -6.9299e-01,\n",
              "             2.7527e-02,  5.2571e-03],\n",
              "           [-1.3691e-01, -1.2817e+00, -7.3394e-01,  ...,  2.1262e-01,\n",
              "             4.1552e-01,  3.9256e-02],\n",
              "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00],\n",
              "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "             0.0000e+00,  0.0000e+00]]], device='cuda:0'),\n",
              "  tensor([[1, 1, 1, 1],\n",
              "          [1, 1, 0, 0]], device='cuda:0'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPDyhS8U6-gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获得三层ELMo编码，每层1024维，维度为3*batch_size(2)*max_sentence_len(4)*1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YunUuOM7XCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e98f6e35-752a-4e17-c789-d9e9dbe3d26a"
      },
      "source": [
        "all_layers = torch.cat([ele[0].unsqueeze(0) for ele in without_bos_eos], dim=0);all_layers"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-7.8914e-01, -5.4923e-01,  1.1545e-01,  ..., -7.5666e-02,\n",
              "            5.1954e-02, -3.3451e-01],\n",
              "          [ 1.9155e-01,  2.2999e-01, -2.8944e-01,  ..., -6.4465e-02,\n",
              "            5.8102e-01,  2.1768e-01],\n",
              "          [ 5.8930e-02, -6.2122e-01,  2.3317e-02,  ...,  6.7177e-01,\n",
              "           -7.3198e-01,  6.7544e-01],\n",
              "          [-8.8715e-01, -2.0040e-01, -1.0601e+00,  ..., -2.6555e-01,\n",
              "            2.1146e-01,  1.9773e-01]],\n",
              "\n",
              "         [[ 1.7428e-01, -1.4072e+00, -1.9392e-01,  ..., -6.6748e-01,\n",
              "           -2.1261e-01,  4.4577e-01],\n",
              "          [-1.3351e+00,  6.2966e-01, -1.4650e+00,  ...,  2.9524e-02,\n",
              "            6.4315e-01,  8.3389e-01],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[-2.6698e-01, -8.8074e-02, -1.5340e-01,  ...,  3.3766e-03,\n",
              "            2.8561e-01, -1.2721e-02],\n",
              "          [-4.8673e-01, -2.5238e-01, -5.3668e-02,  ...,  1.7548e-01,\n",
              "            9.2645e-01,  7.2345e-01],\n",
              "          [-5.7882e-03, -5.9363e-01, -2.8848e-01,  ...,  1.1832e-01,\n",
              "            7.3355e-01,  4.2705e-01],\n",
              "          [-9.7495e-01, -3.5858e-01, -1.0591e-02,  ..., -2.8201e-02,\n",
              "           -1.7668e-02,  6.0000e-02]],\n",
              "\n",
              "         [[ 7.9219e-02, -9.9586e-01, -1.3092e+00,  ..., -3.9311e-01,\n",
              "           -1.9492e-02, -5.9354e-01],\n",
              "          [-4.5405e-01, -1.2215e+00, -1.9299e-01,  ...,  1.9767e-01,\n",
              "            1.3806e-01, -1.9684e-01],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[-1.1359e+00, -1.0042e+00, -3.6454e-01,  ..., -1.5923e-01,\n",
              "            5.8588e-01, -1.4881e-01],\n",
              "          [-1.3656e+00, -9.1023e-01, -8.8036e-02,  ..., -2.6436e-01,\n",
              "            2.5936e+00,  1.9032e+00],\n",
              "          [-4.2545e-01, -7.8282e-01,  1.5677e-01,  ...,  2.5359e-01,\n",
              "            9.6101e-01,  3.5806e-01],\n",
              "          [-7.9414e-01, -4.8740e-01, -1.6544e+00,  ..., -1.0655e-03,\n",
              "           -9.2814e-02,  6.3544e-02]],\n",
              "\n",
              "         [[-3.8214e-01, -1.5724e+00, -1.7789e+00,  ..., -6.9299e-01,\n",
              "            2.7527e-02,  5.2571e-03],\n",
              "          [-1.3691e-01, -1.2817e+00, -7.3394e-01,  ...,  2.1262e-01,\n",
              "            4.1552e-01,  3.9256e-02],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlcVaBSp7pnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 求加权和时每层的权重参数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSEsN5B971CM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16dbcfd8-d0d2-4932-bb08-78132d667dab"
      },
      "source": [
        "s = nn.Parameter(torch.Tensor([1., 1., 1.]), requires_grad=True).cuda();s"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.], device='cuda:0', grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-v_FTE8Dtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 权重和为1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPNfc8_H8KN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5035546f-c6fa-4af0-f6cc-7e425b03ef49"
      },
      "source": [
        "s = F.softmax(s, dim=0);s"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3333, 0.3333, 0.3333], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG8qCA2c8OH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 求加权和时的相乘因子gamma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krvobbc68U-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89cca521-04c0-462a-993b-cd7c8f293477"
      },
      "source": [
        "gamma = nn.Parameter(torch.Tensor(1, 1), requires_grad=True).cuda();gamma"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4041e-34]], device='cuda:0', grad_fn=<CopyBackwards>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ-hpxvM8gZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获得ELMo编码，维度为batch_size(2)*max_sentence_len(4)*1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vb4_H9g8h-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "d4dfc1e3-f2b2-4fb4-8bfe-bc1da19c80a3"
      },
      "source": [
        "res = (all_layers[0]*s[0] + all_layers[1]*s[1] + all_layers[2]*s[2]) * gamma;res"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0259e-34, -7.6826e-35, -1.8838e-35,  ..., -1.0836e-35,\n",
              "           4.3220e-35, -2.3216e-35],\n",
              "         [-7.7731e-35, -4.3649e-35, -2.0179e-35,  ..., -7.1772e-36,\n",
              "           1.9194e-34,  1.3312e-34],\n",
              "         [-1.7425e-35, -9.3497e-35, -5.0731e-36,  ...,  4.8847e-35,\n",
              "           4.5052e-35,  6.8358e-35],\n",
              "         [-1.2432e-34, -4.8974e-35, -1.2754e-34,  ..., -1.3798e-35,\n",
              "           4.7261e-36,  1.5037e-35]],\n",
              "\n",
              "        [[-6.0207e-36, -1.8606e-34, -1.5361e-34,  ..., -8.2073e-35,\n",
              "          -9.5748e-36, -6.6698e-36],\n",
              "         [-9.0147e-35, -8.7691e-35, -1.1195e-34,  ...,  2.0585e-35,\n",
              "           5.6011e-35,  3.1653e-35],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00]]], device='cuda:0', grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6KL8S4y88_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa4506e3-cad5-4ea6-cf49-73634c5d6cc4"
      },
      "source": [
        "res.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfkdhigS9PJa",
        "colab_type": "text"
      },
      "source": [
        "#### 经过大规模语言模型预训练，ELMo获得了有效的上下文表示。与基于机器翻译的CoVe相比，ELMo能够充分利用预训练模型的参数。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ELMoTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python36564bitmrccondaf2fda53e5a1a4db7b763f220d2468ca5",
      "display_name": "Python 3.6.5 64-bit ('MRC': conda)"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
注意力机制最早是在机器视觉领域被提出的。它基于一个直观的想法，即人类在识别图像中物体时并不是观察每个像素，而是集中注意力在图像中某些特定的部分，观察别的物体时，注意力有移动到另外的领域。

同样的道理也可以推广到文本理解中。因此，深度学习在处理文本信息时，可以根据当前的需要将权重集中到某些词语上，而且随着时间推移，这一权重可以自动调整。这就是自然语言理解里的注意力机制。

注意力机制的输入包括两个部分：
	1、被注意的对象，为一组向量{a1, a2, ..., an}，如输入文本的词向量；
	2、一个进行注意的对象，为一个向量x。

向量x需要对{a1, a2, ..., an}进行总结，但是x对每个ai的注意力不一样。注意力